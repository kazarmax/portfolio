{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project to analyze relationship between development team estimates in abstract points (story points) and real calendar and working days.\n",
    "\n",
    "from jira import JIRA\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateutil.parser\n",
    "from datetime import date\n",
    "import plotly.graph_objects as go\n",
    "import math\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "jira = JIRA(basic_auth=('jira_user', 'jira_password'), options={'server': 'jira_server_url'})\n",
    "\n",
    "dev_statuses = ['Development: In progress']\n",
    "\n",
    "default_reversed_search_value = True\n",
    "\n",
    "\n",
    "def get_issue_sp(issue):\n",
    "    return issue.fields.customfield_11212\n",
    "\n",
    "\n",
    "def get_issue_key(issue):\n",
    "    return issue.key\n",
    "\n",
    "\n",
    "def get_issue_title(issue):\n",
    "    return str(issue.fields.summary)\n",
    "\n",
    "\n",
    "def get_issue_resolution_date_str(issue):\n",
    "    return str(issue.fields.resolutiondate)\n",
    "\n",
    "\n",
    "def get_issue_to_status_date(issue, status, reversed_search=default_reversed_search_value):\n",
    "    histories = reversed(issue.changelog.histories) if reversed_search else issue.changelog.histories\n",
    "    for history in histories:\n",
    "        for item in history.items:\n",
    "            if item.field == 'status':\n",
    "                if item.toString.lower() == str(status).lower():\n",
    "                    return history.created\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_issue_from_status_date(issue, status, reversed_search=default_reversed_search_value):\n",
    "    histories = reversed(issue.changelog.histories) if reversed_search else issue.changelog.histories\n",
    "    for history in histories:\n",
    "        for item in history.items:\n",
    "            if item.field == 'status':\n",
    "                if item.fromString.lower() == str(status).lower():\n",
    "                    return history.created\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_duedate_move_info(issue):\n",
    "    tracked_status = 'Developement: In Progress'\n",
    "    if get_issue_to_status_date(issue, tracked_status, reversed_search=False) is None:\n",
    "        return None\n",
    "    issue_dev_start = dateutil.parser.parse(get_issue_to_status_date(issue, tracked_status, reversed_search=False)).replace(tzinfo=None)\n",
    "    issue_dev_end = dateutil.parser.parse(get_issue_from_status_date(issue, tracked_status, reversed_search=True)).replace(tzinfo=None)\n",
    "\n",
    "    histories = issue.changelog.histories\n",
    "    move_dates = []\n",
    "    move_count = 0\n",
    "    \n",
    "    for history in histories:\n",
    "        for item in history.items:\n",
    "            if item.field == 'duedate':\n",
    "                if item.fromString is not None:\n",
    "                    event_date = dateutil.parser.parse(history.created).replace(tzinfo=None)\n",
    "                    if issue_dev_start.date() < event_date.date() < issue_dev_end.date():\n",
    "                        move_count += 1 \n",
    "                        move_dates.append(history.created[:16])\n",
    "                    \n",
    "    return dict(move_count=move_count, move_dates=move_dates)\n",
    "\n",
    "\n",
    "def get_first_duedate_details(issue):\n",
    "    tracked_status = 'Developement: In Progress'\n",
    "    if get_issue_to_status_date(issue, tracked_status, reversed_search=False) is None:\n",
    "        return None\n",
    "    issue_dev_start = dateutil.parser.parse(get_issue_to_status_date(issue, tracked_status, reversed_search=False)).replace(tzinfo=None)\n",
    "    issue_dev_end = dateutil.parser.parse(get_issue_from_status_date(issue, tracked_status, reversed_search=True)).replace(tzinfo=None)\n",
    "    \n",
    "    for history in issue.changelog.histories:\n",
    "        for item in history.items:\n",
    "            if item.field == 'duedate' and item.toString is not None:\n",
    "                duedate = dateutil.parser.parse(item.toString).replace(tzinfo=None)\n",
    "                if duedate > issue_dev_start:\n",
    "                    abs_duedate_error_cd = (issue_dev_end.date() - duedate.date()).days\n",
    "                    rel_duedate_error_cd = int(round((abs_duedate_error_cd / (duedate.date() - issue_dev_start.date()).days), 2) * 100)\n",
    "                    \n",
    "                    return {'duedate':duedate, \n",
    "                            'issue_dev_start':issue_dev_start,\n",
    "                            'issue_dev_end':issue_dev_end,\n",
    "                            'abs_dd_err':abs_duedate_error_cd,\n",
    "                            'rel_dd_err':rel_duedate_error_cd\n",
    "                           }\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_issue_property_change_stats(issue, property_name, property_value, \n",
    "                                    left_limit_date=None, right_limit_date=None):\n",
    "    \n",
    "    prop_change_dates_list = []\n",
    "    prop_change_dates = {}\n",
    "    workdays_total = 0\n",
    "    caldays_total = 0\n",
    "    property_found = False\n",
    "    \n",
    "    ###LOOP START###\n",
    "    for history in issue.changelog.histories:\n",
    "        for item in history.items:\n",
    "            if item.field == property_name:\n",
    "                if item.toString is not None and item.toString.lower() == property_value.lower():\n",
    "                    prop_change_dates['begin_date'] = dateutil.parser.parse(history.created).replace(tzinfo=None)\n",
    "                if item.fromString is not None and item.fromString.lower() == property_value.lower():\n",
    "                    prop_change_dates['end_date'] = dateutil.parser.parse(history.created).replace(tzinfo=None)\n",
    "        \n",
    "        if 'end_date' in prop_change_dates and 'begin_date' in prop_change_dates:\n",
    "            if left_limit_date is not None and right_limit_date is not None:\n",
    "                if prop_change_dates['begin_date'].date() < left_limit_date.date() or prop_change_dates['end_date'].date() > right_limit_date.date():\n",
    "                    prop_change_dates = {}\n",
    "                    continue\n",
    "            property_found = True\n",
    "            workdays_count = np.busday_count(prop_change_dates['begin_date'].date(), prop_change_dates['end_date'].date())\n",
    "            caldays_count = round((prop_change_dates['end_date'] - prop_change_dates['begin_date']).total_seconds()/60/60/24, 2)\n",
    "            workdays_total += workdays_count\n",
    "            caldays_total += caldays_count\n",
    "            prop_change_dates['workdays_count'] = workdays_count\n",
    "            prop_change_dates['caldays_count'] = caldays_count             \n",
    "            prop_change_dates_list.append(prop_change_dates)            \n",
    "            prop_change_dates = {} \n",
    "    ###LOOP END###\n",
    "    \n",
    "    if not property_found:\n",
    "        return None\n",
    "        \n",
    "    return {\"workdays_total\": workdays_total, \"caldays_total\": caldays_total, \"transitions\": prop_change_dates_list}\n",
    "\n",
    "\n",
    "def get_issue_status_change_stats(issue, status):\n",
    "    return get_issue_property_change_stats(issue, 'status', status)\n",
    "    \n",
    "    \n",
    "def get_issue_blocking_stats(issue):\n",
    "    block_search_status = 'Developement: In Progress'\n",
    "    if get_issue_to_status_date(issue, block_search_status, reversed_search=False) is None:\n",
    "        return None\n",
    "    block_search_startdate = dateutil.parser.parse(get_issue_to_status_date(issue, block_search_status, reversed_search=False)).replace(tzinfo=None)\n",
    "    block_search_enddate = dateutil.parser.parse(get_issue_from_status_date(issue, block_search_status, reversed_search=True)).replace(tzinfo=None)\n",
    "    \n",
    "    return get_issue_property_change_stats(issue, 'Flagged', 'Impediment',\n",
    "                                    left_limit_date=block_search_startdate, right_limit_date=block_search_enddate)\n",
    "\n",
    "\n",
    "def get_portfolio_details(portfolio):\n",
    "    \n",
    "    total_caldays = 0\n",
    "    total_workdays = 0\n",
    "    blocking_caldays = 0\n",
    "    blocking_workdays = 0\n",
    "    \n",
    "    for status in dev_statuses:\n",
    "        status_change_stats = get_issue_status_change_stats(portfolio, status)\n",
    "        if status_change_stats:\n",
    "            total_caldays += status_change_stats['caldays_total'] \n",
    "            total_workdays += status_change_stats['workdays_total']\n",
    "    \n",
    "    issue_blocking_stats = get_issue_blocking_stats(portfolio)\n",
    "    if issue_blocking_stats:\n",
    "        blocking_caldays = issue_blocking_stats['caldays_total']\n",
    "        blocking_workdays = issue_blocking_stats['workdays_total']\n",
    "    \n",
    "    caldays_wo_block = total_caldays - blocking_caldays\n",
    "    workdays_wo_block = total_workdays - blocking_workdays\n",
    "    \n",
    "    sp = get_issue_sp(portfolio)\n",
    "    \n",
    "    dd_move_qty = None\n",
    "    dev_start = None\n",
    "    dev_end = None\n",
    "    first_duedate = None\n",
    "    abs_dd_err = None\n",
    "    rel_dd_err = None\n",
    "    if get_first_duedate_details(portfolio) is not None:\n",
    "        dd_move_qty = get_duedate_move_info(portfolio)['move_count']\n",
    "        dev_start = get_first_duedate_details(portfolio)['issue_dev_start']\n",
    "        dev_end = get_first_duedate_details(portfolio)['issue_dev_end']\n",
    "        first_duedate = get_first_duedate_details(portfolio)['duedate']\n",
    "        abs_dd_err = get_first_duedate_details(portfolio)['abs_dd_err']\n",
    "        rel_dd_err = get_first_duedate_details(portfolio)['rel_dd_err']\n",
    "        \n",
    "    to_os_date = get_issue_to_status_date(portfolio, \"Feedback\")\n",
    "            \n",
    "    workdays_wo_block_in_one_sp = round(workdays_wo_block / float(sp), 2) if sp is not None and sp > 0 else None\n",
    "    caldays_wo_block_in_one_sp = round(caldays_wo_block / float(sp), 2) if sp is not None and sp > 0 else None\n",
    "    total_workdays_in_one_sp = round(total_workdays / float(sp), 2) if sp is not None and sp > 0 else None\n",
    "    total_caldays_in_one_sp = round(total_caldays / float(sp), 2) if sp is not None and sp > 0 else None    \n",
    "    \n",
    "    return OrderedDict(\n",
    "        title = get_issue_title(portfolio),\n",
    "        key = get_issue_key(portfolio),\n",
    "        dev_start = dev_start,\n",
    "        dev_end = dev_end,\n",
    "        first_duedate = first_duedate,\n",
    "        abs_dd_err = abs_dd_err,\n",
    "        rel_dd_err = rel_dd_err,\n",
    "        dd_move_qty = dd_move_qty,\n",
    "        resolution_date = to_os_date if to_os_date is not None else get_issue_resolution_date_str(portfolio),\n",
    "        total_wrkdays = total_workdays,\n",
    "        total_cldays = total_caldays,\n",
    "        block_wrkdays = blocking_workdays,\n",
    "        block_cldays = blocking_caldays,\n",
    "        wrkdays_wo_block = workdays_wo_block,\n",
    "        cldays_wo_block = caldays_wo_block,\n",
    "        sp = sp,\n",
    "        wdays_wo_block_in_sp = workdays_wo_block_in_one_sp,\n",
    "        cldays_wo_block_in_sp = caldays_wo_block_in_one_sp,\n",
    "        ttl_wdays_in_sp = total_workdays_in_one_sp,\n",
    "        ttl_cldays_in_sp = total_caldays_in_one_sp\n",
    "    )\n",
    "\n",
    "\n",
    "def get_portfolios_stats(dev_team, begin_date, end_date):\n",
    "\n",
    "    JQL_QUERY = 'project = \"Development\" and type != Epic and \"Development Team\" = \"{}\" and resolutiondate >= {} and resolutiondate <= {} and resolution not in (\"Won\\'t Fix\", Duplicate, \"Hold On\", \"Not a bug\")'.format(dev_team, begin_date, end_date)\n",
    "\n",
    "    portfolios = jira.search_issues(JQL_QUERY, expand='changelog', maxResults=1000)\n",
    "\n",
    "    portfolio_stats_list = []\n",
    "    for portfolio in portfolios:\n",
    "        portfolio_stats_list.append(get_portfolio_details(portfolio))\n",
    "\n",
    "    return portfolio_stats_list\n",
    "\n",
    "\n",
    "def display_scatter(title, xaxis_title, yaxis_title, data_categories, visible_category, x_data, y_data_df_name, \n",
    "                    scatter_mode='markers', line_props=None, marker_size=10):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for data_category in data_categories:\n",
    "        visible_value = True if data_category == visible_category else 'legendonly'\n",
    "        fig.add_trace(go.Scatter(x=x_data,\n",
    "                                y=y_data_df_name[data_category].tolist(),\n",
    "                                mode=scatter_mode,\n",
    "                                marker_size=marker_size,\n",
    "                                line = line_props,\n",
    "                                text=y_data_df_name['title'],\n",
    "                                name = data_category, \n",
    "                                visible = visible_value,\n",
    "                                hovertemplate=\n",
    "                                '<b>text</b>: %{text}<br>' +\n",
    "                                '<b>x</b>: %{x}<br>'+\n",
    "                                '<b>y</b>: %{y}'+\n",
    "                                \"<extra></extra>\")\n",
    "                        )\n",
    "        \n",
    "    fig.update_layout(title=title, xaxis_title=xaxis_title, yaxis_title=yaxis_title)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def show_sp_stats(dev_team, begin_date, end_date, excluded_portfolios=[]):\n",
    "    \n",
    "    ### Get data from portfolios and create pandas dataframes\n",
    "    stats = get_portfolios_stats(dev_team, begin_date, end_date)\n",
    "    full_data = pd.DataFrame(stats)\n",
    "    polished_data = full_data[~full_data.key.isin(excluded_portfolios)]\n",
    "    polished_data = polished_data[polished_data.ttl_cldays_in_sp.notnull()]\n",
    "    full_data['resolution_date'] = pd.to_datetime(full_data['resolution_date'], format=\"%Y-%m-%d %H:%M\").dt.tz_localize(None)\n",
    "    polished_data['resolution_date'] = pd.to_datetime(polished_data['resolution_date'], format=\"%Y-%m-%d %H:%M\").dt.tz_localize(None)\n",
    "    polished_data = polished_data[polished_data['resolution_date'] >= dateutil.parser.parse(begin_date)]\n",
    "    \n",
    "    ### Display pandas dataframe with full data from portfolios and short stats about portfolios quantity\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  \n",
    "        display(full_data.sort_values(by='ttl_cldays_in_sp', ascending=False).style.format({'key': __make_clickable__}))\n",
    "    print('Initial number of tasks: {} | Number of excluded tasks: {} | Number of tasks chosen for analysis: {}'.format(len(full_data), len(full_data) - len(polished_data), len(polished_data)))\n",
    "    if (len(full_data) - len(polished_data) > 0):\n",
    "        print('\\nExcluded tasks')\n",
    "        display(full_data[~full_data.isin(polished_data)].dropna(how = 'all'))\n",
    "\n",
    "    \n",
    "    ### Prepare data and display dataframe with stats on average sp size in dev days\n",
    "    dev_days_types = ['wrkdays_wo_block', 'cldays_wo_block', 'total_wrkdays', 'total_cldays']\n",
    "    avg_sp_days_data = OrderedDict()\n",
    "    for dev_days_type in dev_days_types:\n",
    "        avg_sp_days_data[dev_days_type] = [round(polished_data[dev_days_type].sum() / polished_data.sp.sum(), 2)]\n",
    "    display(HTML('<br><h4>Average SP size in days</h4>'))\n",
    "    display(pd.DataFrame(avg_sp_days_data).transpose())\n",
    "    \n",
    "    ### Prepare data and display dataframe with stats on sp size in dev days by procentiles\n",
    "    percentile_scale = [50, 75, 85, 100]\n",
    "    percentile_scale_labels = [\"{}%\".format(prc) for prc in percentile_scale]\n",
    "    sp_size_types = ['wdays_wo_block_in_sp', 'cldays_wo_block_in_sp', 'ttl_wdays_in_sp', 'ttl_cldays_in_sp']\n",
    "    sp_days_procentiles_data = OrderedDict()\n",
    "    sp_days_procentiles_data['procentile'] = percentile_scale_labels\n",
    "    for sp_size_type in sp_size_types:\n",
    "        sp_days_procentiles_data[sp_size_type] = [round(np.percentile(sorted(polished_data[sp_size_type].tolist()), prc), 2) for prc in percentile_scale]\n",
    "    display(HTML('<br><h4>SP size in days by procentiles</h4>'))\n",
    "    display(pd.DataFrame(sp_days_procentiles_data))\n",
    "    \n",
    "    ### Display scatter plot of relationship btw portfolio size in sp and portfolio dev days\n",
    "    display_scatter(title='\"SP - portfolio dev days\" relationship', \n",
    "                    xaxis_title='Portfolio size, SP', \n",
    "                    yaxis_title='Portfolio dev days', \n",
    "                    data_categories=dev_days_types, \n",
    "                    visible_category='wrkdays_wo_block',\n",
    "                    x_data=polished_data.sp.tolist(), \n",
    "                    y_data_df_name=polished_data)\n",
    "    \n",
    "    ### Display scatter plot of relationship btw portfolio size in sp and days in 1sp\n",
    "    display_scatter(title='\"SP - #of dev days in 1SP\" relationship',\n",
    "                    xaxis_title='Portfolio size, SP',\n",
    "                    yaxis_title='Number of dev days in 1 sp', \n",
    "                    data_categories=sp_size_types, \n",
    "                    visible_category='wdays_wo_block_in_sp',\n",
    "                    x_data=polished_data.sp.tolist(), \n",
    "                    y_data_df_name=polished_data)\n",
    "    \n",
    "    ### Display scatterplot of dev days in 1 sp dynamics\n",
    "    data_by_date = polished_data.sort_values(by='resolution_date')\n",
    "    display_scatter(title='Dev days in 1 sp dynamics',\n",
    "                    xaxis_title='Portfolio resolution date',\n",
    "                    yaxis_title='Dev days in 1 sp', \n",
    "                    data_categories=sp_size_types, \n",
    "                    visible_category='wdays_wo_block_in_sp',\n",
    "                    x_data=data_by_date.resolution_date.tolist(), \n",
    "                    y_data_df_name=data_by_date,\n",
    "                    scatter_mode='lines+markers',\n",
    "                    line_props=dict(width=2, dash='dot'),\n",
    "                    marker_size=9)\n",
    "    \n",
    "    ### Display scatter plot of relationship btw portfolio size in sp and duedate moves qty\n",
    "    display_scatter(title='\"SP - duedate moves\" relationship', \n",
    "                    xaxis_title='Portfolio size, SP', \n",
    "                    yaxis_title='Portfolio due date moves qty', \n",
    "                    data_categories=['dd_move_qty'], \n",
    "                    visible_category='dd_move_qty',\n",
    "                    x_data=polished_data.sp.tolist(), \n",
    "                    y_data_df_name=polished_data)\n",
    "    \n",
    "    ### Display scatter plot of relationship btw portfolio size in sp and duedate error in days\n",
    "    ### Duedate error is calculated as (dev_end_date - first duedate)\n",
    "    display_scatter(title='\"SP - duedate error\" relationship', \n",
    "                    xaxis_title='Portfolio size, SP', \n",
    "                    yaxis_title='Portfolio duedate error, сdays and %', \n",
    "                    data_categories=['abs_dd_err', 'rel_dd_err'], \n",
    "                    visible_category='abs_dd_err',\n",
    "                    x_data=polished_data.sp.tolist(), \n",
    "                    y_data_df_name=polished_data)\n",
    "    \n",
    "    \n",
    "def __make_clickable__(val):\n",
    "        return '<a href=\"{}\" target=\"_blank\">{}</a>'.format(\"https://jira.hh.ru/browse/\"+val, val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "today = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "dev_team = 'Clickme'\n",
    "begin_date = '2019-06-01'\n",
    "end_date = today\n",
    "show_sp_stats(dev_team, begin_date, end_date, excluded_portfolios=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def get_shifted_date(start_date, days_offset, use_workdays=True):\n",
    "    day_increment = datetime.timedelta(1)\n",
    "    calculated_date = dateutil.parser.parse(start_date)\n",
    "    count = 0\n",
    "    while count < days_offset:\n",
    "        calculated_date += day_increment\n",
    "        if use_workdays:\n",
    "            if calculated_date.weekday() <= 4:\n",
    "                count += 1\n",
    "        else:\n",
    "            count += 1\n",
    "    return calculated_date\n",
    "\n",
    "\n",
    "### Fill parameters below to calculate duedate\n",
    "\n",
    "dev_start_date      = '2019-11-25'    ### use format \"yyyy-mm-dd\"\n",
    "portfolio_size_sp   = 13              ### portfolio size in sp\n",
    "days_in_sp          = 2.82            ### size of sp in days\n",
    "use_workdays        = True            ### use True in case of workdays, or False - if calend days\n",
    "\n",
    "\n",
    "num_of_days = math.ceil(portfolio_size_sp * days_in_sp)\n",
    "print(\"Forecast to complete project:\", get_shifted_date(dev_start_date, num_of_days, use_workdays).strftime(\"%d.%m.%Y\"))\n",
    "print(\"Number of days:\", num_of_days)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
