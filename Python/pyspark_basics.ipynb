{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SF Fire Calls\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_schema = StructType([StructField('CallNumber', IntegerType(), True),\n",
    "                     StructField('UnitID', StringType(), True),\n",
    "                     StructField('IncidentNumber', IntegerType(), True),\n",
    "                     StructField('CallType', StringType(), True),                  \n",
    "                     StructField('CallDate', StringType(), True),      \n",
    "                     StructField('WatchDate', StringType(), True),\n",
    "                     StructField('CallFinalDisposition', StringType(), True),\n",
    "                     StructField('AvailableDtTm', StringType(), True),\n",
    "                     StructField('Address', StringType(), True),       \n",
    "                     StructField('City', StringType(), True),       \n",
    "                     StructField('Zipcode', IntegerType(), True),       \n",
    "                     StructField('Battalion', StringType(), True),                 \n",
    "                     StructField('StationArea', StringType(), True),       \n",
    "                     StructField('Box', StringType(), True),       \n",
    "                     StructField('OriginalPriority', StringType(), True),       \n",
    "                     StructField('Priority', StringType(), True),       \n",
    "                     StructField('FinalPriority', IntegerType(), True),       \n",
    "                     StructField('ALSUnit', BooleanType(), True),       \n",
    "                     StructField('CallTypeGroup', StringType(), True),\n",
    "                     StructField('NumAlarms', IntegerType(), True),\n",
    "                     StructField('UnitType', StringType(), True),\n",
    "                     StructField('UnitSequenceInCallDispatch', IntegerType(), True),\n",
    "                     StructField('FirePreventionDistrict', StringType(), True),\n",
    "                     StructField('SupervisorDistrict', StringType(), True),\n",
    "                     StructField('Neighborhood', StringType(), True),\n",
    "                     StructField('Location', StringType(), True),\n",
    "                     StructField('RowID', StringType(), True),\n",
    "                     StructField('Delay', FloatType(), True)])\n",
    "\n",
    "sf_fire_file = \"data/sf-fire-calls.csv\"\n",
    "fire_df = spark.read.csv(sf_fire_file, header=True, schema=fire_schema)\n",
    "\n",
    "# Cache the DataFrame since we will be performing some operations on it.\n",
    "fire_df.cache()\n",
    "fire_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the dataframe schema\n",
    "fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" sql\\n\\nselect IncidentNumber, AvailableDtTm, CallType\\nfrom fire_calls\\nwhere CallType != 'Medical Incident'\\nlimit 5;\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_fire_df = (fire_df\n",
    "               .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\")\n",
    "               .where(F.col(\"CallType\") != \"Medical Incident\"))\n",
    "\n",
    "few_fire_df.show(5, truncate=False)\n",
    "\n",
    "''' sql\n",
    "\n",
    "select IncidentNumber, AvailableDtTm, CallType\n",
    "from fire_calls\n",
    "where CallType != 'Medical Incident'\n",
    "limit 5;\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DistinctCallTypes|\n",
      "+-----------------+\n",
      "|               30|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-1) How many distinct types of calls were made to the Fire Department?\n",
    "# To be sure, let's not count \"null\" strings in that column.\n",
    "\n",
    "(fire_df\n",
    "  .select(\"CallType\")\n",
    "  .where(F.col(\"CallType\").isNotNull())\n",
    "  .agg(F.countDistinct(\"CallType\").alias(\"DistinctCallTypes\"))\n",
    "  .show())\n",
    "\n",
    "'''\n",
    "SQL:\n",
    "\n",
    "select count(distinct calltype) as DistinctCallTypes \n",
    "from fire_calls \n",
    "where calltype is not null \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            CallType|\n",
      "+--------------------+\n",
      "|Elevator / Escala...|\n",
      "|         Marine Fire|\n",
      "|  Aircraft Emergency|\n",
      "|      Administrative|\n",
      "|              Alarms|\n",
      "|Odor (Strange / U...|\n",
      "|Citizen Assist / ...|\n",
      "|              HazMat|\n",
      "|Watercraft in Dis...|\n",
      "|           Explosion|\n",
      "|           Oil Spill|\n",
      "|        Vehicle Fire|\n",
      "|  Suspicious Package|\n",
      "|Extrication / Ent...|\n",
      "|               Other|\n",
      "|        Outside Fire|\n",
      "|   Traffic Collision|\n",
      "|       Assist Police|\n",
      "|Gas Leak (Natural...|\n",
      "|        Water Rescue|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#sql\\nselect distinct calltype \\nfrom fire_calls \\nwhere calldate is not null \\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q-2) What are distinct types of calls were made to the Fire Department?\n",
    "# These are all the distinct type of call to the SF Fire Department\n",
    "\n",
    "#pyspark\n",
    "(fire_df\n",
    "  .select(\"CallType\")\n",
    "  .where(F.col(\"CallType\").isNotNull())\n",
    "  .distinct()\n",
    "  .show())\n",
    "\n",
    "'''\n",
    "#sql\n",
    "select distinct calltype \n",
    "from fire_calls \n",
    "where calltype is not null \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-3) Find out all response or delayed times greater than 5 mins?\n",
    "# Rename the column Delay - > ReponseDelayedinMins\n",
    "# Returns a new DataFrame\n",
    "# Find out all calls where the response time to the fire site was delayed for more than 5 mins\n",
    "\n",
    "new_fire_df = fire_df.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")\n",
    "(new_fire_df\n",
    "  .select(\"ResponseDelayedinMins\")\n",
    "  .where(F.col(\"ResponseDelayedinMins\") > 5)\n",
    "  .show(5, False))\n",
    "\n",
    "'''\n",
    "#sql\n",
    "select Delay as ReponseDelayedinMins\n",
    "from fire_calls \n",
    "where Delay > 5\n",
    "limit 5\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+---------+\n",
      "|CallType        |Zipcode|calls_qty|\n",
      "+----------------+-------+---------+\n",
      "|Medical Incident|94102  |16130    |\n",
      "|Medical Incident|94103  |14775    |\n",
      "|Medical Incident|94110  |9995     |\n",
      "|Medical Incident|94109  |9479     |\n",
      "|Medical Incident|94124  |5885     |\n",
      "+----------------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#sql\\n\\nselect \\ncalltype, zipcode, count(*) as calls_qty\\nfrom fire_calls\\ngroup by 1, 2\\norder by 3 desc \\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q-4a) What zip codes accounted for most common calls?\n",
    "# Let's investigate what zip codes in San Francisco accounted for most fire calls and what type where they.\n",
    "# Filter out by CallType\n",
    "# Group them by CallType and Zip code\n",
    "# Count them and display them in descending order\n",
    "\n",
    "(fire_df\n",
    "  .select(\"CallType\", \"Zipcode\")\n",
    "  .groupBy(\"CallType\", \"Zipcode\")\n",
    "  .agg(F.count(\"*\").alias(\"calls_qty\"))\n",
    "  .orderBy(F.col(\"calls_qty\").desc()) \n",
    "  .show(5, False)\n",
    "  )\n",
    "\n",
    "\n",
    "'''\n",
    "#sql\n",
    "\n",
    "select calltype, zipcode, count(*) as calls_qty\n",
    "from fire_calls\n",
    "group by calltype, zipcode\n",
    "order by count(*) desc \n",
    "limit 5;\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------+\n",
      "|Neighborhood                  |incident_qty|\n",
      "+------------------------------+------------+\n",
      "|Tenderloin                    |17408       |\n",
      "|South of Market               |14016       |\n",
      "|Mission                       |5445        |\n",
      "|Hayes Valley                  |2867        |\n",
      "|Financial District/South Beach|1536        |\n",
      "+------------------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n#sql\\n\\nselect neighborhood, count(incidentnumber) as incident_qty\\nfrom fire_calls\\nwhere zipcode in ('94102', '94103')\\ngroup by neighborhood\\norder by count(incidentnumber) desc\\nlimit 5;\\n\\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q-4b) What San Francisco neighborhoods are in the zip codes 94102 and 94103\n",
    "# Let's find out the neighborhoods associated with these two zip codes. In all likelihood, these are some of the contested neighborhood with high reported crimes.\n",
    "\n",
    "(fire_df\n",
    "  .where(F.col(\"Zipcode\").isin('94102', '94103')) \n",
    "  .groupBy(\"Neighborhood\")\n",
    "  .agg(F.count(\"IncidentNumber\").alias(\"incident_qty\")) \n",
    "  .orderBy(F.col(\"incident_qty\").desc()) \n",
    "  .show(5, False)\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "#sql\n",
    "\n",
    "select neighborhood, count(incidentnumber) as incident_qty\n",
    "from fire_calls\n",
    "where zipcode in ('94102', '94103')\n",
    "group by neighborhood\n",
    "order by count(incidentnumber) desc\n",
    "limit 5;\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+---------+-----------------+\n",
      "|total_alarms|  min_delay|max_delay|        avg_delay|\n",
      "+------------+-----------+---------+-----------------+\n",
      "|      176170|0.016666668|  1844.55|3.892364154521585|\n",
      "+------------+-----------+---------+-----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#sql\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q-5) What was the sum of all calls, average, min and max of the response times for calls?\n",
    "# Let's use the built-in Spark SQL functions to compute the sum, avg, min, and max of few columns:\n",
    "# Number of Total Alarms\n",
    "# What were the min and max the delay in response time before the Fire Dept arrived at the scene of the call\n",
    "\n",
    "(fire_df\n",
    "    .select(\n",
    "      F.sum(\"numalarms\").alias(\"total_alarms\"),\n",
    "      F.min(\"Delay\").alias(\"min_delay\"),\n",
    "      F.max(\"Delay\").alias(\"max_delay\"),\n",
    "      F.avg(\"Delay\").alias(\"avg_delay\") )\n",
    "  .show()\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "#sql\n",
    "\n",
    "select \n",
    "sum(numalarms) as total_alarms,\n",
    "min(delay) as min_delay,\n",
    "max(delay) as max_delay,\n",
    "avg(delay) as avg_delay\n",
    "from fire_calls\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|week|calls_qty|\n",
      "+----+---------+\n",
      "|  22|      259|\n",
      "+----+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#sql\\n\\nselect \\nweekofyear(calldate) as week,\\ncount(*) as calls_qty\\nfrom fire_calls\\nwhere year(calldate) = 2018\\ngroup by week\\norder by calls_qty desc\\nlimit 1;\\n\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ** Q-6b) What week of the year in 2018 had the most fire calls?**\n",
    "# Note: Week 1 is the New Years' week and week 25 is the July 4 the week. Loads of fireworks, so it makes sense the higher number of calls.\n",
    "\n",
    "# Convert \"CallDate\" field type from string to a date.\n",
    "\n",
    "fire_df = fire_df.withColumn('CallDate', F.to_timestamp(F.col(\"CallDate\"), 'MM/dd/yyyy'))\n",
    "\n",
    "(fire_df\n",
    "  .where(F.year(\"CallDate\") == 2018)\n",
    "  .groupBy(F.weekofyear(\"CallDate\").alias(\"week\"))\n",
    "  .agg(F.count(\"*\").alias(\"calls_qty\"))\n",
    "  .orderBy(F.col(\"calls_qty\").desc())\n",
    "  .show(1)\n",
    " )\n",
    " \n",
    "\n",
    "'''\n",
    "#sql\n",
    "\n",
    "select \n",
    "weekofyear(calldate) as week,\n",
    "count(*) as calls_qty\n",
    "from fire_calls\n",
    "where year(calldate) = 2018\n",
    "group by week\n",
    "order by calls_qty desc\n",
    "limit 1;\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|   Neighborhood|         avg_delay|\n",
      "+---------------+------------------+\n",
      "|Treasure Island|11.320833250880241|\n",
      "|       Presidio| 6.248148073752721|\n",
      "|      Chinatown| 6.158818309742307|\n",
      "+---------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n#sql\\n\\nselect\\nneighborhood, avg(delay) as avg_delay\\nfrom fire_calls \\nwhere year(calldate) = 2018 and city = 'San Francisco'\\ngroup by neighborhood\\norder by avg_delay desc \\nlimit 3\\n\\n\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ** Q-7) What neighborhoods in San Francisco had the worst response time in 2018?**\n",
    "# It appears that if you living in Presidio Heights, the Fire Dept arrived in less than 3 mins, while Mission Bay took more than 6 mins.\n",
    "\n",
    "(fire_df\n",
    " .where((F.year(\"CallDate\") == 2018) & (F.col(\"City\") == 'San Francisco'))\n",
    " .groupby(F.col(\"Neighborhood\"))\n",
    " .agg(F.avg(\"Delay\").alias(\"avg_delay\"))\n",
    " .orderBy(F.col(\"avg_delay\").desc())\n",
    " .show(3)\n",
    " )\n",
    "\n",
    "\n",
    "'''\n",
    "#sql\n",
    "\n",
    "select\n",
    "neighborhood, avg(delay) as avg_delay\n",
    "from fire_calls \n",
    "where year(calldate) = 2018 and city = 'San Francisco'\n",
    "group by neighborhood\n",
    "order by avg_delay desc \n",
    "limit 3\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|IS_RETURNED|      ORDER_ID|\n",
      "+-----------+--------------+\n",
      "|       true|CA-2016-100762|\n",
      "|       true|CA-2016-100762|\n",
      "|       true|CA-2016-100762|\n",
      "|       true|CA-2016-100762|\n",
      "|       true|CA-2016-100867|\n",
      "|       true|CA-2016-102652|\n",
      "|       true|CA-2016-102652|\n",
      "|       true|CA-2016-102652|\n",
      "|       true|CA-2016-102652|\n",
      "|       true|CA-2016-103373|\n",
      "|       true|CA-2016-103744|\n",
      "|       true|CA-2016-103744|\n",
      "|       true|CA-2016-103940|\n",
      "|       true|CA-2016-103940|\n",
      "|       true|CA-2016-103940|\n",
      "|       true|CA-2016-103940|\n",
      "|       true|CA-2016-104829|\n",
      "|       true|CA-2016-105270|\n",
      "|       true|CA-2016-105270|\n",
      "|       true|CA-2016-108609|\n",
      "+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ** Q-8a) How can we use SQL table to store data and read it back?**\n",
    "#  connect to Snowflake from pyspark and read one table to dataframe\n",
    "\n",
    "# pyspark --packages net.snowflake:snowflake-jdbc:3.14.5,net.snowflake:spark-snowflake_2.12:2.12.0-spark_3.4\n",
    "\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Set the PYSPARK_SUBMIT_ARGS environment variable\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages net.snowflake:snowflake-jdbc:3.14.5,net.snowflake:spark-snowflake_2.12:2.12.0-spark_3.4 pyspark-shell'\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"SnowflakeTest\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#print(spark.sparkContext.getConf().getAll()) #for troubleshooting driver issue\n",
    "\n",
    "# Define Snowflake connection options\n",
    "sfURL = os.getenv('SF_URL') \n",
    "sfAccount = os.getenv('SF_ACCOUNT')\n",
    "sfUser = os.getenv('SF_USER')\n",
    "sfPassword = os.getenv('SF_PASSWORD')\n",
    "\n",
    "options = {\n",
    "    \"sfURL\": sfURL,\n",
    "    \"sfAccount\": sfAccount,\n",
    "    \"sfUser\": sfUser,\n",
    "    \"sfPassword\": sfPassword,\n",
    "    \"sfDatabase\": \"RAW\",\n",
    "    \"sfSchema\": \"SUPERSTORE\",\n",
    "    \"sfWarehouse\": \"WH_SUPERSTORE\"\n",
    "}\n",
    "\n",
    "# Specify the Snowflake source\n",
    "SNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\n",
    "\n",
    "# Load data from Snowflake\n",
    "df = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n",
    "    .options(**options) \\\n",
    "    .option(\"query\", \"SELECT * FROM returned_orders\") \\\n",
    "    .load()\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+-----------+\n",
      "|IS_RETURNED|      ORDER_ID|return_date|\n",
      "+-----------+--------------+-----------+\n",
      "|       true|CA-2016-100762| 2024-02-09|\n",
      "|       true|CA-2016-100762| 2024-02-09|\n",
      "|       true|CA-2016-100762| 2024-02-09|\n",
      "|       true|CA-2016-100762| 2024-02-09|\n",
      "|       true|CA-2016-100867| 2024-02-09|\n",
      "|       true|CA-2016-102652| 2024-02-09|\n",
      "|       true|CA-2016-102652| 2024-02-09|\n",
      "|       true|CA-2016-102652| 2024-02-09|\n",
      "|       true|CA-2016-102652| 2024-02-09|\n",
      "|       true|CA-2016-103373| 2024-02-09|\n",
      "|       true|CA-2016-103744| 2024-02-09|\n",
      "|       true|CA-2016-103744| 2024-02-09|\n",
      "|       true|CA-2016-103940| 2024-02-09|\n",
      "|       true|CA-2016-103940| 2024-02-09|\n",
      "|       true|CA-2016-103940| 2024-02-09|\n",
      "|       true|CA-2016-103940| 2024-02-09|\n",
      "|       true|CA-2016-104829| 2024-02-09|\n",
      "|       true|CA-2016-105270| 2024-02-09|\n",
      "|       true|CA-2016-105270| 2024-02-09|\n",
      "|       true|CA-2016-108609| 2024-02-09|\n",
      "+-----------+--------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add the 'return_date' column with the current date\n",
    "df_with_date = df.withColumn(\"return_date\", F.current_date())\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df_with_date.show()\n",
    "\n",
    "# Specify the target Snowflake table for writing the data\n",
    "target_table = \"returned_orders_with_date\"\n",
    "\n",
    "# Write the updated DataFrame back to Snowflake. Mode can be \"overwrite\" or \"append\"\n",
    "df_with_date.write \\\n",
    "    .format(SNOWFLAKE_SOURCE_NAME) \\\n",
    "    .options(**options) \\\n",
    "    .option(\"dbtable\", target_table) \\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+----------+----------+--------------+-----------+------------------+-----------+-------------+---------------+--------------+-----------+-------+---------------+---------------+------------+--------------------+------------------+--------+--------+-------------------+\n",
      "|Row ID|      Order ID|Order Date| Ship Date|     Ship Mode|Customer ID|     Customer Name|    Segment|      Country|           City|         State|Postal Code| Region|     Product ID|       Category|Sub-Category|        Product Name|             Sales|Quantity|Discount|             Profit|\n",
      "+------+--------------+----------+----------+--------------+-----------+------------------+-----------+-------------+---------------+--------------+-----------+-------+---------------+---------------+------------+--------------------+------------------+--------+--------+-------------------+\n",
      "|     1|CA-2018-152156|2018-11-08|2018-11-07|  Second Class|   CG-12520|       Claire Gute|   Consumer|United States|      Henderson|      Kentucky|    42420.0|  South|FUR-BO-10001798|      Furniture|   Bookcases|Bush Somerset Col...|            261.96|       2|     0.0|            41.9136|\n",
      "|     2|CA-2018-152156|2018-11-08|2018-11-11|  Second Class|   CG-12520|       Claire Gute|   Consumer|United States|      Henderson|      Kentucky|    42420.0|  South|FUR-CH-10000454|      Furniture|      Chairs|Hon Deluxe Fabric...| 731.9399999999999|       3|     0.0|            219.582|\n",
      "|     3|CA-2018-138688|2018-06-12|2018-06-16|  Second Class|   DV-13045|   Darrin Van Huff|  Corporate|United States|    Los Angeles|    California|    90036.0|   West|OFF-LA-10000240|Office Supplies|      Labels|Self-Adhesive Add...|             14.62|       2|     0.0|             6.8714|\n",
      "|     4|US-2017-108966|2017-10-11|2017-10-18|Standard Class|   SO-20335|    Sean O'Donnell|   Consumer|United States|Fort Lauderdale|       Florida|    33311.0|  South|FUR-TA-10000577|      Furniture|      Tables|Bretford CR4500 S...|          957.5775|       5|    0.45|-383.03100000000006|\n",
      "|     5|US-2017-108966|2017-10-11|2017-10-18|Standard Class|   SO-20335|    Sean O'Donnell|   Consumer|United States|Fort Lauderdale|       Florida|    33311.0|  South|OFF-ST-10000760|Office Supplies|     Storage|Eldon Fold 'N Rol...|            22.368|       2|     0.2|  2.516399999999999|\n",
      "|     6|CA-2016-115812|2016-06-09|2016-06-14|Standard Class|   BH-11710|   Brosina Hoffman|   Consumer|United States|    Los Angeles|    California|    90032.0|   West|FUR-FU-10001487|      Furniture| Furnishings|Eldon Expressions...|             48.86|       7|     0.0| 14.169399999999996|\n",
      "|     7|CA-2016-115812|2016-06-09|2016-06-14|Standard Class|   BH-11710|   Brosina Hoffman|   Consumer|United States|    Los Angeles|    California|    90032.0|   West|OFF-AR-10002833|Office Supplies|         Art|          Newell 322|              7.28|       4|     0.0|             1.9656|\n",
      "|     8|CA-2016-115812|2016-06-09|2016-06-14|Standard Class|   BH-11710|   Brosina Hoffman|   Consumer|United States|    Los Angeles|    California|    90032.0|   West|TEC-PH-10002275|     Technology|      Phones|Mitel 5320 IP Pho...|           907.152|       6|     0.2|  90.71520000000004|\n",
      "|     9|CA-2016-115812|2016-06-09|2016-06-14|Standard Class|   BH-11710|   Brosina Hoffman|   Consumer|United States|    Los Angeles|    California|    90032.0|   West|OFF-BI-10003910|Office Supplies|     Binders|DXL Angle-View Bi...|            18.504|       3|     0.2|             5.7825|\n",
      "|    10|CA-2016-115812|2016-06-09|2016-06-14|Standard Class|   BH-11710|   Brosina Hoffman|   Consumer|United States|    Los Angeles|    California|    90032.0|   West|OFF-AP-10002892|Office Supplies|  Appliances|Belkin F5C206VTEL...|             114.9|       5|     0.0|  34.46999999999999|\n",
      "|    11|CA-2016-115812|2016-06-09|2016-06-14|Standard Class|   BH-11710|   Brosina Hoffman|   Consumer|United States|    Los Angeles|    California|    90032.0|   West|FUR-TA-10001539|      Furniture|      Tables|Chromcraft Rectan...|1706.1840000000002|       9|     0.2|   85.3091999999998|\n",
      "|    12|CA-2016-115812|2016-06-09|2016-06-14|Standard Class|   BH-11710|   Brosina Hoffman|   Consumer|United States|    Los Angeles|    California|    90032.0|   West|TEC-PH-10002033|     Technology|      Phones|Konftel 250 Confe...|           911.424|       4|     0.2|  68.35680000000002|\n",
      "|    13|CA-2019-114412|2019-04-15|2019-04-20|Standard Class|   AA-10480|      Andrew Allen|   Consumer|United States|        Concord|North Carolina|    28027.0|  South|OFF-PA-10002365|Office Supplies|       Paper|          Xerox 1967|15.552000000000003|       3|     0.2|             5.4432|\n",
      "|    14|CA-2018-161389|2018-12-05|2018-12-10|Standard Class|   IM-15070|      Irene Maddox|   Consumer|United States|        Seattle|    Washington|    98103.0|   West|OFF-BI-10003656|Office Supplies|     Binders|Fellowes PB200 Pl...|407.97600000000006|       3|     0.2|  132.5921999999999|\n",
      "|    15|US-2017-118983|2017-11-22|2017-11-26|Standard Class|   HP-14815|     Harold Pawlan|Home Office|United States|     Fort Worth|         Texas|    76106.0|Central|OFF-AP-10002311|Office Supplies|  Appliances|Holmes Replacemen...| 68.80999999999999|       5|     0.8|           -123.858|\n",
      "|    16|US-2017-118983|2017-11-22|2017-11-26|Standard Class|   HP-14815|     Harold Pawlan|Home Office|United States|     Fort Worth|         Texas|    76106.0|Central|OFF-BI-10000756|Office Supplies|     Binders|Storex DuraTech R...|             2.544|       3|     0.8|-3.8160000000000016|\n",
      "|    17|CA-2016-105893|2016-11-11|2016-11-18|Standard Class|   PK-19075|         Pete Kriz|   Consumer|United States|        Madison|     Wisconsin|    53711.0|Central|OFF-ST-10004186|Office Supplies|     Storage|Stur-D-Stor Shelv...|            665.88|       6|     0.0|            13.3176|\n",
      "|    18|CA-2016-167164|2016-05-13|2016-05-15|  Second Class|   AG-10270|   Alejandro Grove|   Consumer|United States|    West Jordan|          Utah|    84084.0|   West|OFF-ST-10000107|Office Supplies|     Storage|Fellowes Super St...|              55.5|       2|     0.0|  9.989999999999997|\n",
      "|    19|CA-2016-143336|2016-08-27|2016-09-01|  Second Class|   ZD-21925|Zuschuss Donatelli|   Consumer|United States|  San Francisco|    California|    94109.0|   West|OFF-AR-10003056|Office Supplies|         Art|          Newell 341|              8.56|       2|     0.0| 2.4823999999999997|\n",
      "|    20|CA-2016-143336|2016-08-27|2016-09-01|  Second Class|   ZD-21925|Zuschuss Donatelli|   Consumer|United States|  San Francisco|    California|    94109.0|   West|TEC-PH-10001949|     Technology|      Phones|Cisco SPA 501G IP...|            213.48|       3|     0.2|  16.01099999999998|\n",
      "+------+--------------+----------+----------+--------------+-----------+------------------+-----------+-------------+---------------+--------------+-----------+-------+---------------+---------------+------------+--------------------+------------------+--------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ** Q-8c) How can read data from Parquet file?**\n",
    "\n",
    "# Path to the Parquet file\n",
    "parquet_file_path = './data/supestore_orders.parquet'\n",
    "\n",
    "# Read the Parquet file\n",
    "df = spark.read.parquet(parquet_file_path)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
